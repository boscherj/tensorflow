{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_Tf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boscherj/tensorflow/blob/master/iris_Tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "OTeZWA9VgT-k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "#  you may not use this file except in compliance with the License.\n",
        "#  You may obtain a copy of the License at\n",
        "#\n",
        "#   http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "#  Unless required by applicable law or agreed to in writing, software\n",
        "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "#  See the License for the specific language governing permissions and\n",
        "#  limitations under the License.\n",
        "\"\"\"An Example of a DNNClassifier for the Iris dataset.\"\"\"\n",
        "\n",
        "# https://www.tensorflow.org/get_started/get_started_for_beginners\n",
        "# J'ai modifié l'exemple Getting Started for ML Beginners\n",
        "# J'ai supprimé le import iris_data et j'ai intégré ici les fonctions définies dans le fichier iris_data\n",
        "# Je commente à la fois le Python et le TensorFlow\n",
        "\n",
        "# https://docs.python.org/2/library/__future__.html\n",
        "# __future__ is a real module, and serves three purposes:\n",
        "# To avoid confusing existing tools that analyze import statements and expect to find the modules they’re importing.\n",
        "# To ensure that future statements run under releases prior to 2.1 at least yield runtime exceptions \n",
        "# (the import of __future__ will fail, because there was no module of that name prior to 2.1).\n",
        "# To document when incompatible changes were introduced, and when they will be — or were — made mandatory. \n",
        "# This is a form of executable documentation, and can be inspected programmatically via \n",
        "# importing __future__ and examining its contents.\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# https://docs.python.org/3/library/argparse.html#argumentparser-objects\n",
        "# parser = argparse.ArgumentParser()\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MBwI_hqMiQ30",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://docs.python.org/3/library/argparse.html#argparse.ArgumentParser.add_argument\n",
        "# parser.add_argument('--batch_size', default=100, type=int, help='batch size')\n",
        "# parser.add_argument('--train_steps', default=1000, type=int, help='number of training steps')\n",
        "# J'ai remplacé le argv par des constantes\n",
        "\n",
        "# Test set accuracy: 0.967 si je mets CONST_BATCH_SIZE = 100\n",
        "# Test set accuracy: 0.967 si je mets CONST_BATCH_SIZE = 1000\n",
        "# CONST_BATCH_SIZE = 1000 par défaut\n",
        "CONST_BATCH_SIZE = 1000\n",
        "\n",
        "# Test set accuracy: 0.533 si je mets CONST_BATCH_SIZE = 1000 et CONST_TRAINING_STEPS = 10\n",
        "# Test set accuracy: 0.533 si je mets CONST_BATCH_SIZE = 1000 et CONST_TRAINING_STEPS = 200\n",
        "# Si je mets CONST_TRAINING_STEPS = 50 alors Test set accuracy: 0.833\n",
        "\n",
        "# CONST_TRAINING_STEPS = 100 par défaut\n",
        "CONST_TRAINING_STEPS = 100\n",
        "\n",
        "\n",
        "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
        "# 120,4,setosa,versicolor,virginica\n",
        "# 6.4,2.8,5.6,2.2,2\n",
        "# 5.0,2.3,3.3,1.0,1\n",
        "# 4.9,2.5,4.5,1.7,2\n",
        "# ...\n",
        "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
        "# 30,4,setosa,versicolor,virginica\n",
        "# 5.9,3.0,4.2,1.5,1\n",
        "# 6.9,3.1,5.4,2.1,2\n",
        "# 5.1,3.3,1.7,0.5,0\n",
        "# 6.0,3.4,4.5,1.6,1\n",
        "\n",
        "# 0 represents setosa\n",
        "# 1 represents versicolor\n",
        "# 2 represents virginica\n",
        "\n",
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
        "                    'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nYKpD8P2iVKO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def maybe_download():\n",
        "    \n",
        "    # https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file\n",
        "    # Downloads a file from a URL if it not already in the cache.\n",
        "\n",
        "    # By default the file at the url origin is downloaded to the cache_dir ~/.keras, placed in \n",
        "    # the cache_subdir datasets, and given the filename fname. \n",
        "    # The final location of a file example.txt would therefore be ~/.keras/datasets/example.txt.\n",
        "    # get_file(\n",
        "    #   fname,\n",
        "    #   origin,\n",
        "    # ...\n",
        "    # )\n",
        "    # On fait d'abord un split sur /\n",
        "    # TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
        "    # ['http:', '', 'download.tensorflow.org', 'data', 'iris_training.csv']\n",
        "    # Puis [-1] pour obtenir le dernier élément de la liste, soit iris_training.csv ici\n",
        "    # Le résultat obtenu pour train_path est sur mon Mac : /Users/xxx/.keras/datasets/iris_training.csv\n",
        "    train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)\n",
        "    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
        "\n",
        "    return train_path, test_path\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eJzvrE6iiYcb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(y_name='Species'):\n",
        "    \"\"\"Returns the iris dataset as (train_x, train_y), (test_x, test_y).\"\"\"\n",
        "    train_path, test_path = maybe_download()\n",
        "\n",
        "    train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "    # train : \n",
        "    #\n",
        "    #     SepalLength  SepalWidth  PetalLength  PetalWidth\n",
        "    # 0            6.4         2.8          5.6         2.2\n",
        "    # 1            5.0         2.3          3.3         1.0\n",
        "    # 2            4.9         2.5          4.5         1.7\n",
        "    # 3            4.9         3.1          1.5         0.1\n",
        "    # ...\n",
        "    # https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pop.html\n",
        "    # Return item and drop from frame. \n",
        "    train_x, train_y = train, train.pop(y_name)\n",
        "\n",
        "    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "    \n",
        "    # https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pop.html\n",
        "    # Return item and drop from frame. \n",
        "    test_x, test_y = test, test.pop(y_name)\n",
        "\n",
        "    return (train_x, train_y), (test_x, test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "78ygzRfmij77",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_input_fn(features, labels, batch_size):\n",
        "    \"\"\"An input function for training\"\"\"\n",
        "    # Convert the inputs to a Dataset.\n",
        "    # Creates a Dataset whose elements are slices of the given tensors.\n",
        "    # https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/data/Dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # Shuffle, repeat, and batch the examples.\n",
        "    # Randomly shuffles the elements of this dataset.\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "    # buffer_size: A tf.int64 scalar tf.Tensor, representing the number of elements from this dataset\n",
        "    # from which the new dataset will sample.\n",
        "    dataset = dataset.shuffle(CONST_BATCH_SIZE).repeat().batch(batch_size)\n",
        "\n",
        "    # Build the Iterator, and return the read end of the pipeline.\n",
        "    # https://www.tensorflow.org/programmers_guide/datasets#creating_an_iterator\n",
        "    # A one-shot iterator is the simplest form of iterator, which only supports iterating \n",
        "    # once through a dataset, with no need for explicit initialization. One-shot iterators handle \n",
        "    # almost all of the cases that the existing queue-based input pipelines support, \n",
        "    # but they do not support parameterization.\n",
        "    \n",
        "    # Creates an Iterator for enumerating the elements of this dataset.\n",
        "    # https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/data/Dataset\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "    # Creates an Iterator for enumerating the elements of this dataset.\n",
        "    return dataset.make_one_shot_iterator().get_next()\n",
        "    # return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cwUnNK8yim5V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eval_input_fn(features, labels, batch_size):\n",
        "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
        "    features=dict(features)\n",
        "    \n",
        "    if labels is None:\n",
        "        # No labels, use only features.\n",
        "        inputs = features\n",
        "    else:\n",
        "        inputs = (features, labels)\n",
        "    \n",
        "\n",
        "    # Convert the inputs to a Dataset.\n",
        "    # dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "    # dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "\n",
        "    # Batch the examples\n",
        "    assert batch_size is not None, \"batch_size must not be None\"\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    # Return the dataset.\n",
        "    # return dataset\n",
        "    return dataset.make_one_shot_iterator().get_next()\n",
        "    # return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uDEZIp98yOjm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# On peut aussi lire les données avec sklearn mais je ne vais pas le faire car \n",
        "# je veux être sur que le training set et le test set restent composés comme \n",
        "# dans l'exercice\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "data.DESCR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r-5BQwhg3z2e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ---------------------- C'est ici que ça commence ----------------------\n",
        "#\n",
        "#\n",
        "# -----------------------------------------------------------------------\n",
        "\n",
        "# Je ne trouve pas de doc assez claire sur le tf.logging.INFO\n",
        "# tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "(train_x, train_y), (test_x, test_y) = load_data() \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mc01oIsS32xb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6316043e-a5b1-4505-da63-afeed22396d2"
      },
      "cell_type": "code",
      "source": [
        "train_x.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
              "0          6.4         2.8          5.6         2.2\n",
              "1          5.0         2.3          3.3         1.0\n",
              "2          4.9         2.5          4.5         1.7\n",
              "3          4.9         3.1          1.5         0.1\n",
              "4          5.7         3.8          1.7         0.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "YElI69fF3-Zc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "32a24188-1b84-46b6-e5a9-32e95724fc5b"
      },
      "cell_type": "code",
      "source": [
        "train_y.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2\n",
              "1    1\n",
              "2    2\n",
              "3    0\n",
              "4    0\n",
              "Name: Species, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "PBzEHDMB4HWh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8d4abfae-0c94-4616-9a74-f66b5b656c44"
      },
      "cell_type": "code",
      "source": [
        "test_x.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
              "0          5.9         3.0          4.2         1.5\n",
              "1          6.9         3.1          5.4         2.1\n",
              "2          5.1         3.3          1.7         0.5\n",
              "3          6.0         3.4          4.5         1.6\n",
              "4          5.5         2.5          4.0         1.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "8EqMmVsD4Ojq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c4349348-6a5d-4311-a810-47f940847db7"
      },
      "cell_type": "code",
      "source": [
        "test_y.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    2\n",
              "2    0\n",
              "3    1\n",
              "4    1\n",
              "Name: Species, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "Yp7YJizK4Y5I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Feature columns describe how to use the input.\n",
        "# A feature column is a data structure that tells your model how to interpret the data \n",
        "# in each feature. In the Iris problem, we want the model to interpret the data in each feature \n",
        "# as its literal floating-point value; that is, we want the model to interpret an input value \n",
        "# like 5.4 as, well, 5.4. However, in other machine learning problems, it is often desirable to interpret data less literally.\n",
        "\n",
        "my_feature_columns = []\n",
        "\n",
        "# my_feature_columns \n",
        "# \t[\n",
        "# \t\t_NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), \n",
        "# \t\t_NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), \n",
        "# \t\t_NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), \n",
        "# \t\t_NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
        "# \t]\n",
        "for key in train_x.keys():\n",
        "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CxUg5Iuv4b_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9bbcf066-aa71-4965-fae1-063c1dccce5e"
      },
      "cell_type": "code",
      "source": [
        "my_feature_columns"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "P5teZyY74ogS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "2bb603e5-9ad0-42dc-c801-94f5610de41a"
      },
      "cell_type": "code",
      "source": [
        "# Build 2 hidden layer DNN with 10, 10 units respectively.\n",
        "# To implement a neural network, the premade_estimators.py program uses a pre-made Estimator \n",
        "# named tf.estimator.DNNClassifier. This Estimator builds a neural network that classifies examples. \n",
        "# Nous avons un Réseau de Neurons avec 3 couches \n",
        "# Chaque couche a 10 neurons\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=my_feature_columns,\n",
        "    # Two hidden layers of 10 nodes each.\n",
        "    # Use the hidden_units parameter to define the number of neurons in each hidden layer of the neural network. \n",
        "    # The length of the list assigned to hidden_units identifies the number of hidden layers (2, in this case). \n",
        "    # Each value in the list represents the number of neurons in a particular hidden \n",
        "    # layer (10 in the first hidden layer and 10 in the second hidden layer). \n",
        "    # To change the number of hidden layers or neurons, simply assign a different list to the hidden_units parameter.\n",
        "    \n",
        "    hidden_units=[10, 10],\n",
        "    # The model must choose between 3 classes.\n",
        "    n_classes=3)\n",
        "\n",
        "# Train the Model.\n",
        "# classifier.train(input_fn=lambda:iris_data.train_input_fn(train_x, train_y,100),steps=1000)\n",
        "classifier.train(input_fn=lambda:train_input_fn(train_x, train_y, CONST_BATCH_SIZE), steps=CONST_TRAINING_STEPS)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp9qayr03c\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp9qayr03c', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5f1b6ac160>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp9qayr03c/model.ckpt.\n",
            "INFO:tensorflow:loss = 2941.3, step = 1\n",
            "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmp9qayr03c/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 261.4186.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x7f5f1b6ac780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "sJlBpzabipYd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "3d0f353f-8dbd-4e99-9e1d-f265999c95e8"
      },
      "cell_type": "code",
      "source": [
        "# Evaluate the model.\n",
        "eval_result = classifier.evaluate(input_fn=lambda:eval_input_fn(test_x, test_y, CONST_BATCH_SIZE))\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-04-23T15:49:00Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp9qayr03c/model.ckpt-100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-04-23-15:49:00\n",
            "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.96666664, average_loss = 0.31874135, global_step = 100, loss = 9.562241\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/tmp9qayr03c/model.ckpt-100\n",
            "\n",
            "Test set accuracy: 0.967\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kRktbQbwiveI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate predictions from the model\n",
        "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "predict_x = {\n",
        "    'SepalLength': [5.1, 5.9, 6.9],\n",
        "    'SepalWidth': [3.3, 3.0, 3.1],\n",
        "    'PetalLength': [1.7, 4.2, 5.4],\n",
        "    'PetalWidth': [0.5, 1.5, 2.1],\n",
        "}\n",
        "\n",
        "# \tSepalLength\t\tSepalWidth\tPetalLength\t\tPetalWidth\n",
        "# \t\t5.1\t\t\t3.3\t\t\t\t1.7\t\t\t\t0.5\n",
        "# \t\t5.9\t\t\t3.0\t\t\t\t4.2\t\t\t\t1.5\n",
        "# \t\t6.9\t\t\t3.1\t\t\t\t5.4\t\t\t\t2.1\n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier\n",
        "predictions = classifier.predict(input_fn=lambda:eval_input_fn(predict_x,labels=None,batch_size=CONST_BATCH_SIZE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qj4dhlHfiGs9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# zip\n",
        "# This function returns a list of tuples, where the i-th tuple contains the i-th element from each of \n",
        "# the argument sequences or iterables. The returned list is truncated in length to the length of the \n",
        "# shortest argument sequence. When there are multiple arguments which are all of the same length, \n",
        "# zip() is similar to map() with an initial argument of None. \n",
        "# With a single sequence argument, it returns a list of 1-tuples. With no arguments, it returns an empty list.\n",
        "\n",
        "# >>> x = [1, 2, 3]\n",
        "# >>> y = [4, 5, 6]\n",
        "# >>> zipped = zip(x, y)\n",
        "# >>> zipped\n",
        "# [(1, 4), (2, 5), (3, 6)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zXxQsQ-hhiFs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "433fadfa-8d0b-41a5-fe9c-b984f4f54791"
      },
      "cell_type": "code",
      "source": [
        "for pred_dict, expec in zip(predictions, expected):\n",
        "    template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "    print(template.format(SPECIES[class_id], 100 * probability, expec))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp9qayr03c/model.ckpt-100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "Prediction is \"Setosa\" (97.6%), expected \"Setosa\"\n",
            "\n",
            "Prediction is \"Versicolor\" (59.5%), expected \"Versicolor\"\n",
            "\n",
            "Prediction is \"Virginica\" (73.5%), expected \"Virginica\"\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}